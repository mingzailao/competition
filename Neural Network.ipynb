{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Activation,Dropout,Input\n",
    "from sklearn import cross_validation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from store.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "store = pd.HDFStore('store.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print the item in store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method HDFStore.items of <class 'pandas.io.pytables.HDFStore'>\n",
      "File path: store.h5\n",
      "/data                             frame        (shape->[1000,9443]) \n",
      "/feature_score                    series       (shape->[28329])     \n",
      "/feature_selected_data            frame        (shape->[1000,3169]) \n",
      "/gene_info                        frame        (shape->[300,9443])  \n",
      "/label                            frame        (shape->[1000,1])    \n",
      "/onehot_data                      frame        (shape->[1000,28329])\n",
      "/selected_idx                     series       (shape->[28329])     >\n"
     ]
    }
   ],
   "source": [
    "print store.items\n",
    "data=store['onehot_data']\n",
    "label=store['label']\n",
    "selected_idx=store['selected_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dl/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:2: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "X = data.as_matrix()\n",
    "X_new2 = X[:,selected_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close the store.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seperate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(label)\n",
    "target=enc.transform(label).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use sklearn.cross_validation.train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data,target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_img = Input(shape=(X_train.shape[1],))\n",
    "encoded = Dense(8000, activation='relu')(input_img)\n",
    "encoded = Dense(2000, activation='relu')(encoded)\n",
    "encoded = Dense(500, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(2000, activation='relu')(encoded)\n",
    "decoded = Dense(8000, activation='relu')(decoded)\n",
    "decoded = Dense(X_train.shape[1], activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(X_train.values,X_train.values,\n",
    "                verbose=1,\n",
    "                nb_epoch=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test.values, X_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print autoencoder.get_weights()[0].shape\n",
    "print autoencoder.get_weights()[1].shape\n",
    "print autoencoder.get_weights()[2].shape\n",
    "print autoencoder.get_weights()[3].shape\n",
    "print autoencoder.get_weights()[4].shape\n",
    "print autoencoder.get_weights()[5].shape\n",
    "print autoencoder.get_weights()[6].shape\n",
    "print autoencoder.get_weights()[7].shape\n",
    "print autoencoder.get_weights()[8].shape\n",
    "print autoencoder.get_weights()[9].shape\n",
    "print autoencoder.get_weights()[10].shape\n",
    "print autoencoder.get_weights()[11].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Keras to build the Nets\n",
    "[None,28329]->[None,8000]->[None,2000]->[None,500]->[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8000, input_dim=X_train.shape[1],weights=[autoencoder.get_weights()[0],autoencoder.get_weights()[1]],activation='relu'))\n",
    "\n",
    "model.add(Dense(2000,input_dim=8000,weights=[autoencoder.get_weights()[2],autoencoder.get_weights()[3]],activation='relu'))\n",
    "\n",
    "model.add(Dense(500,input_dim=2000,weights=[autoencoder.get_weights()[4],autoencoder.get_weights()[5]],activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(2,input_dim=500,activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.0, nesterov=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train.values,y_train,batch_size=100,nb_epoch=500,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
